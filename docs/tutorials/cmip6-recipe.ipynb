{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetCDF Zarr Sequential Recipe: CMIP6\n",
    "\n",
    "This tutorial describes how to create a suitable recipe for many of the CMIP6 datasets.\n",
    "The source data is a sequence of NetCDF files accessed from the 's3://esgf-world' bucket.\n",
    "The target is a Zarr store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "- The s3://esgf-world bucket has about 250,000 datasets stored in about 950,000 netcdf files (for an average of about four netcdf files per dataset). This is a small subset of the WCRP-CMIP6 collection available at the Federated ESGF-COG nodes such as https://esgf-node.llnl.gov/search/cmip6, but it is faster and easier to work with. \n",
    "\n",
    "- Each CMIP6 dataset can be identified by a 6-tuple consisting of:\n",
    "\n",
    "        (model,experiment,ensemble_member,mip_table,variable,grid_label)\n",
    "        \n",
    "and so a convenient name for a particular dataset is a string of these values joined with a '.' separator:\n",
    "\n",
    "      dataset = model.experiment.ensemble_member.mip_table.variable.grid_label\n",
    "        \n",
    "\n",
    "- There can be multiple versions of a dataset, designated by a string beginning with 'v' and then an 8 digit date, loosely associated with its creation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Get to know your source data\n",
    "The CMIP6 collection is very heterogeneous, so getting to know the source data is rather complicated. We first need to identify a dataset and learn how to list the set of netcdf files which are associated with it. Fortunately, you can explore the data here: https://esgf-world.s3.amazonaws.com/index.html#CMIP6/ or download a CSV file listing all of the netcdf files, one per line.\n",
    "\n",
    "Here we will read the CSV file into a pandas dataframe so we can search, sort and subset the available datasets and their netcdf files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 949541 entries, 0 to 949540\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   project          949541 non-null  object\n",
      " 1   institute        949541 non-null  object\n",
      " 2   model            949541 non-null  object\n",
      " 3   experiment_id    949541 non-null  object\n",
      " 4   frequency        461707 non-null  object\n",
      " 5   modeling_realm   461707 non-null  object\n",
      " 6   mip_table        949541 non-null  object\n",
      " 7   ensemble_member  949541 non-null  object\n",
      " 8   grid_label       949541 non-null  object\n",
      " 9   variable         949541 non-null  object\n",
      " 10  temporal subset  920892 non-null  object\n",
      " 11  version          949541 non-null  object\n",
      " 12  path             949541 non-null  object\n",
      "dtypes: object(13)\n",
      "memory usage: 94.2+ MB\n"
     ]
    }
   ],
   "source": [
    "netcdf_cat = 's3://cmip6-nc/esgf-world.csv.gz'\n",
    "df_s3 = pd.read_csv(netcdf_cat, dtype='unicode')\n",
    "df_s3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "      <th>institute</th>\n",
       "      <th>model</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>frequency</th>\n",
       "      <th>modeling_realm</th>\n",
       "      <th>mip_table</th>\n",
       "      <th>ensemble_member</th>\n",
       "      <th>grid_label</th>\n",
       "      <th>variable</th>\n",
       "      <th>temporal subset</th>\n",
       "      <th>version</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CMIP6</td>\n",
       "      <td>AS-RCEC</td>\n",
       "      <td>TaiESM1</td>\n",
       "      <td>histSST-piNTCF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AERmon</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>gn</td>\n",
       "      <td>ps</td>\n",
       "      <td>185001-201412</td>\n",
       "      <td>v20200318</td>\n",
       "      <td>s3://esgf-world/CMIP6/AerChemMIP/AS-RCEC/TaiES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMIP6</td>\n",
       "      <td>AS-RCEC</td>\n",
       "      <td>TaiESM1</td>\n",
       "      <td>histSST-piNTCF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CFmon</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>gn</td>\n",
       "      <td>ta</td>\n",
       "      <td>185001-201412</td>\n",
       "      <td>v20200318</td>\n",
       "      <td>s3://esgf-world/CMIP6/AerChemMIP/AS-RCEC/TaiES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMIP6</td>\n",
       "      <td>AS-RCEC</td>\n",
       "      <td>TaiESM1</td>\n",
       "      <td>histSST-piNTCF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LImon</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>gn</td>\n",
       "      <td>snc</td>\n",
       "      <td>185002-201412</td>\n",
       "      <td>v20200318</td>\n",
       "      <td>s3://esgf-world/CMIP6/AerChemMIP/AS-RCEC/TaiES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CMIP6</td>\n",
       "      <td>AS-RCEC</td>\n",
       "      <td>TaiESM1</td>\n",
       "      <td>histSST-piNTCF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LImon</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>gn</td>\n",
       "      <td>snd</td>\n",
       "      <td>185002-201412</td>\n",
       "      <td>v20200318</td>\n",
       "      <td>s3://esgf-world/CMIP6/AerChemMIP/AS-RCEC/TaiES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CMIP6</td>\n",
       "      <td>AS-RCEC</td>\n",
       "      <td>TaiESM1</td>\n",
       "      <td>histSST-piNTCF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LImon</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>gn</td>\n",
       "      <td>snw</td>\n",
       "      <td>185002-201412</td>\n",
       "      <td>v20200318</td>\n",
       "      <td>s3://esgf-world/CMIP6/AerChemMIP/AS-RCEC/TaiES...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  project institute    model   experiment_id frequency modeling_realm  \\\n",
       "0   CMIP6   AS-RCEC  TaiESM1  histSST-piNTCF       NaN            NaN   \n",
       "1   CMIP6   AS-RCEC  TaiESM1  histSST-piNTCF       NaN            NaN   \n",
       "2   CMIP6   AS-RCEC  TaiESM1  histSST-piNTCF       NaN            NaN   \n",
       "3   CMIP6   AS-RCEC  TaiESM1  histSST-piNTCF       NaN            NaN   \n",
       "4   CMIP6   AS-RCEC  TaiESM1  histSST-piNTCF       NaN            NaN   \n",
       "\n",
       "  mip_table ensemble_member grid_label variable temporal subset    version  \\\n",
       "0    AERmon        r1i1p1f1         gn       ps   185001-201412  v20200318   \n",
       "1     CFmon        r1i1p1f1         gn       ta   185001-201412  v20200318   \n",
       "2     LImon        r1i1p1f1         gn      snc   185002-201412  v20200318   \n",
       "3     LImon        r1i1p1f1         gn      snd   185002-201412  v20200318   \n",
       "4     LImon        r1i1p1f1         gn      snw   185002-201412  v20200318   \n",
       "\n",
       "                                                path  \n",
       "0  s3://esgf-world/CMIP6/AerChemMIP/AS-RCEC/TaiES...  \n",
       "1  s3://esgf-world/CMIP6/AerChemMIP/AS-RCEC/TaiES...  \n",
       "2  s3://esgf-world/CMIP6/AerChemMIP/AS-RCEC/TaiES...  \n",
       "3  s3://esgf-world/CMIP6/AerChemMIP/AS-RCEC/TaiES...  \n",
       "4  s3://esgf-world/CMIP6/AerChemMIP/AS-RCEC/TaiES...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So there are 949,541 entries, one for each netcdf file. We can see the first five here:\n",
    "# The 'path' column is the most important - you may need to scroll the window to see it!\n",
    "\n",
    "df_s3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241675"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will add a new column which is our short name for the datasets (may take a moment for all 949541 rows)\n",
    "df_s3['dataset'] = df_s3['dataset'] = df_s3.apply(lambda row: '.'.join(row.path.split('/')[6:12]),axis=1)\n",
    "# the number of unique dataset names can be found using the 'nunique' method\n",
    "df_s3.dataset.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://esgf-world/CMIP6/AerChemMIP/AS-RCEC/TaiESM1/histSST-piNTCF/r1i1p1f1/AERmon/ps/gn/v20200318/ps_AERmon_TaiESM1_histSST-piNTCF_r1i1p1f1_gn_185001-201412.nc'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The value in the `path` column of the first row is:\n",
    "df_s3.path.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TaiESM1.histSST-piNTCF.r1i1p1f1.AERmon.ps.gn'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which has the short name:\n",
    "df_s3.dataset.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI-ESM2-0.piClim-SO2.r1i1p1f1.Amon.rlds.gn ['v20190912' 'v20200114']\n",
      "CanESM5.historical.r23i1p1f1.Lmon.gpp.gn ['v20190306' 'v20190429']\n",
      "IPSL-CM6A-LR.abrupt-4xCO2.r1i1p1f1.Lmon.cLeaf.gr ['v20180727' 'v20181005' 'v20190118']\n",
      "IPSL-CM6A-LR.piControl.r1i1p1f1.CFsubhr.rsdscs.gn ['v20180802' 'v20181022']\n",
      "CESM2.amip.r1i1p1f1.AERmon.mmrbc.gn ['v20190218' 'v20190319']\n",
      "GFDL-CM4.abrupt-4xCO2.r1i1p1f1.Lmon.mrro.gr1 ['v20180319' 'v20180701']\n",
      "CanESM5.hist-aer.r8i1p1f1.Amon.va.gn ['v20190306' 'v20190429']\n",
      "CanESM5.hist-volc.r9i1p1f1.Amon.va.gn ['v20190306' 'v20190429']\n",
      "CanESM5.ssp245-GHG.r9i1p1f1.Omon.fgo2.gn ['v20190306' 'v20190429']\n",
      "CanESM5.ssp119.r1i1p1f1.Omon.no3.gn ['v20190306' 'v20190429']\n",
      "CanESM5.ssp370.r1i1p1f1.Amon.uas.gn ['v20190306' 'v20190429']\n",
      "CanESM5.ssp434.r2i1p1f1.Omon.tauvo.gn ['v20190306' 'v20190429']\n",
      "CanESM5.ssp534-over.r1i1p1f1.Lmon.nbp.gn ['v20190306' 'v20190429']\n",
      "CNRM-ESM2-1.ssp585.r1i1p1f2.Emon.loadss.gr ['v20190328' 'v20191021']\n"
     ]
    }
   ],
   "source": [
    "# some datasets have multiple versions: (will just check one in each 500 of them ...)\n",
    "for dataset in df_s3.dataset.unique()[::500]:\n",
    "    df_dataset = df_s3[df_s3.dataset==dataset]\n",
    "    if df_dataset.version.nunique() > 1:\n",
    "        print(dataset,df_dataset.version.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So pick a dataset, any dataset, and try it!  N.B. some datasets are VERY large - especially the day, 6hourly, etc.\n",
    "#dataset = df_s3.dataset[10450]\n",
    "# or:\n",
    "dataset = 'GFDL-CM4.historical.r1i1p1f1.Amon.tas.gr1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "      <th>institute</th>\n",
       "      <th>model</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>frequency</th>\n",
       "      <th>modeling_realm</th>\n",
       "      <th>mip_table</th>\n",
       "      <th>ensemble_member</th>\n",
       "      <th>grid_label</th>\n",
       "      <th>variable</th>\n",
       "      <th>temporal subset</th>\n",
       "      <th>version</th>\n",
       "      <th>path</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>460531</th>\n",
       "      <td>CMIP6</td>\n",
       "      <td>NOAA-GFDL</td>\n",
       "      <td>GFDL-CM4</td>\n",
       "      <td>historical</td>\n",
       "      <td>mon</td>\n",
       "      <td>atmos</td>\n",
       "      <td>Amon</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>gr1</td>\n",
       "      <td>tas</td>\n",
       "      <td>185001-185412</td>\n",
       "      <td>v20180301</td>\n",
       "      <td>s3://esgf-world/CMIP6/CMIP/NOAA-GFDL/GFDL-CM4/...</td>\n",
       "      <td>GFDL-CM4.historical.r1i1p1f1.Amon.tas.gr1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460532</th>\n",
       "      <td>CMIP6</td>\n",
       "      <td>NOAA-GFDL</td>\n",
       "      <td>GFDL-CM4</td>\n",
       "      <td>historical</td>\n",
       "      <td>mon</td>\n",
       "      <td>atmos</td>\n",
       "      <td>Amon</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>gr1</td>\n",
       "      <td>tas</td>\n",
       "      <td>185001-194912</td>\n",
       "      <td>v20180701</td>\n",
       "      <td>s3://esgf-world/CMIP6/CMIP/NOAA-GFDL/GFDL-CM4/...</td>\n",
       "      <td>GFDL-CM4.historical.r1i1p1f1.Amon.tas.gr1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460533</th>\n",
       "      <td>CMIP6</td>\n",
       "      <td>NOAA-GFDL</td>\n",
       "      <td>GFDL-CM4</td>\n",
       "      <td>historical</td>\n",
       "      <td>mon</td>\n",
       "      <td>atmos</td>\n",
       "      <td>Amon</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>gr1</td>\n",
       "      <td>tas</td>\n",
       "      <td>195001-201412</td>\n",
       "      <td>v20180701</td>\n",
       "      <td>s3://esgf-world/CMIP6/CMIP/NOAA-GFDL/GFDL-CM4/...</td>\n",
       "      <td>GFDL-CM4.historical.r1i1p1f1.Amon.tas.gr1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       project  institute     model experiment_id frequency modeling_realm  \\\n",
       "460531   CMIP6  NOAA-GFDL  GFDL-CM4    historical       mon          atmos   \n",
       "460532   CMIP6  NOAA-GFDL  GFDL-CM4    historical       mon          atmos   \n",
       "460533   CMIP6  NOAA-GFDL  GFDL-CM4    historical       mon          atmos   \n",
       "\n",
       "       mip_table ensemble_member grid_label variable temporal subset  \\\n",
       "460531      Amon        r1i1p1f1        gr1      tas   185001-185412   \n",
       "460532      Amon        r1i1p1f1        gr1      tas   185001-194912   \n",
       "460533      Amon        r1i1p1f1        gr1      tas   195001-201412   \n",
       "\n",
       "          version                                               path  \\\n",
       "460531  v20180301  s3://esgf-world/CMIP6/CMIP/NOAA-GFDL/GFDL-CM4/...   \n",
       "460532  v20180701  s3://esgf-world/CMIP6/CMIP/NOAA-GFDL/GFDL-CM4/...   \n",
       "460533  v20180701  s3://esgf-world/CMIP6/CMIP/NOAA-GFDL/GFDL-CM4/...   \n",
       "\n",
       "                                          dataset  \n",
       "460531  GFDL-CM4.historical.r1i1p1f1.Amon.tas.gr1  \n",
       "460532  GFDL-CM4.historical.r1i1p1f1.Amon.tas.gr1  \n",
       "460533  GFDL-CM4.historical.r1i1p1f1.Amon.tas.gr1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset = df_s3[df_s3.dataset==dataset]\n",
    "df_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So this looks good \n",
    "- this dataset is split over 3 netcdf files - see any trouble here?\n",
    "- lets do a quick sanity check (make sure one and only one variable is specified) and get only the latest version of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variable is: tas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['s3://esgf-world/CMIP6/CMIP/NOAA-GFDL/GFDL-CM4/historical/r1i1p1f1/Amon/tas/gr1/v20180701/tas_Amon_GFDL-CM4_historical_r1i1p1f1_gr1_185001-194912.nc',\n",
       " 's3://esgf-world/CMIP6/CMIP/NOAA-GFDL/GFDL-CM4/historical/r1i1p1f1/Amon/tas/gr1/v20180701/tas_Amon_GFDL-CM4_historical_r1i1p1f1_gr1_195001-201412.nc']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvars = df_dataset.variable.unique()\n",
    "assert len(dvars) > 0, 'no netcdf files found for this dataset'\n",
    "assert len(dvars) == 1, f\"trouble with this dataset, too many datasets found: {dvars}\"\n",
    "    \n",
    "var = dvars[0]\n",
    "print('The variable is:',var)\n",
    "\n",
    "# make sure we are looking at the last available version:\n",
    "last_version = sorted(df_dataset.version.unique())[-1]\n",
    "dze = df_dataset[df_dataset.version == last_version].reset_index(drop=True)\n",
    "\n",
    "input_urls = sorted(dze.path.unique())\n",
    "input_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are only two files - one netcdf file was from an older version!\n",
    "- We want to look at the first netcdf file to make sure we know what to expect\n",
    "- To use `xarray.open_dataset`, we need to turn the input_url (starting with 's3://') into an appropriate file_like object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to AWS S3 storage\n",
    "fs_s3 = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "file_url = fs_s3.open(input_urls[0], mode='rb')\n",
    "ds = xr.open_dataset(file_url)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Deciding how to chunk the dataset\n",
    "- For parallel I/O and subsetting the dataset in time, we will chunk the data in the time dimension\n",
    "- In order to figure out the number of time slices in each chunk, we do a small calculation on the first netcdf file\n",
    "- Here we set the desired chunk size to 100 Mb, but something between 50-200 Mb is usually alright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntime = len(ds.time)       # the number of time slices\n",
    "chunksize_optimal = 100e6  # desired chunk size in bytes\n",
    "ncfile_size = ds.nbytes    # the netcdf file size\n",
    "chunksize = max(int(ntime* chunksize_optimal/ ncfile_size),1)\n",
    "\n",
    "target_chunks = ds.dims.mapping\n",
    "target_chunks['time'] = chunksize\n",
    "\n",
    "target_chunks   # a dictionary giving the chunk sizes in each dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Defining a pre-processing function\n",
    "- This is an optional step which we want to apply to each chunk\n",
    "- Here we change some data variables into coordinate variables, but you can define your own pre-processing step here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the netcdf lists some of the coordinate variables as data variables. This is a fix which we want to apply to each chunk.\n",
    "def set_bnds_as_coords(ds):\n",
    "    new_coords_vars = [var for var in ds.data_vars if 'bnds' in var or 'bounds' in var]\n",
    "    ds = ds.set_coords(new_coords_vars)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Choose and define the recipe\n",
    "- The list of input_urls, the sequence_dim and target_chunks are specified as in previous tutorial\n",
    "- These netcdf files do not contain a fixed number of time slices in each file, so we set `nitems_per_input = None`\n",
    "- Some datasets have inconsistent coordinates between the various netcdf files (staggered). In this case, we want the recipe to fail\n",
    "- The current recipe fails for some files unless we use `xarray_open_kwargs = {'decode_coords':False}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a Recipe:\n",
    "from pangeo_forge.recipe import NetCDFtoZarrSequentialRecipe\n",
    "\n",
    "recipe = NetCDFtoZarrSequentialRecipe(\n",
    "    input_urls = input_urls,\n",
    "    sequence_dim = \"time\", \n",
    "    target_chunks = target_chunks,\n",
    "    nitems_per_input = None, \n",
    "    process_chunk = set_bnds_as_coords,\n",
    "    #xarray_open_kwargs = {'decode_coords':False},\n",
    "    xarray_concat_kwargs = {'join':'exact'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create storage targets\n",
    "- Here we are caching the netcdf files locally\n",
    "- We also need a temporary metadata cache because we don't know in advance how many time slices are in each netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from fsspec.implementations.local import LocalFileSystem\n",
    "from pangeo_forge.storage import FSSpecTarget, CacheFSSpecTarget\n",
    "\n",
    "fs_local = LocalFileSystem()\n",
    "\n",
    "target_dir = tempfile.TemporaryDirectory()\n",
    "target = FSSpecTarget(fs_local, target_dir.name)\n",
    "\n",
    "cache_dir = tempfile.TemporaryDirectory()\n",
    "cache_target = CacheFSSpecTarget(fs_local, cache_dir.name)\n",
    "\n",
    "meta_dir = tempfile.TemporaryDirectory()\n",
    "meta_store = FSSpecTarget(fs_local, meta_dir.name)\n",
    "\n",
    "recipe.target = target\n",
    "recipe.input_cache = cache_target\n",
    "recipe.metadata_cache = meta_store\n",
    "\n",
    "cache_target.root_path, target.root_path, meta_store.root_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Execute the recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "\n",
    "if True:\n",
    "    # if caching the input:  (must also use if metadata_caching?)\n",
    "    for input_name in recipe.iter_inputs():\n",
    "        recipe.cache_input(input_name)\n",
    "\n",
    "    # use recipe to create the zarr store:\n",
    "    recipe.prepare_target() \n",
    "    \n",
    "    # is it there?\n",
    "    zgroup = zarr.open(target_dir.name)\n",
    "    print(zgroup.tree())\n",
    "    \n",
    "    for chunk in recipe.iter_chunks():\n",
    "        recipe.store_chunk(chunk)\n",
    "    recipe.finalize_target()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Check the resulting Zarr store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if it worked:\n",
    "ds = xr.open_zarr(target_dir.name)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nc_time_axis\n",
    "ds[var][-1].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postscript\n",
    "- We would like to keep track of datasets for which this recipe does not work and report them somewhere ...\n",
    "- Here is an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Troubles found:\n",
    "\n",
    "dataset = 'IPSL-CM6A-LR.abrupt-4xCO2.r1i1p1f1.Lmon.cLeaf.gr'  # need decode_coords=False in xr.open_dataset, but using xarray_open_kwargs = {'decode_coords':False}, still throws an error when caching the input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo-forge3.8",
   "language": "python",
   "name": "pangeo-forge3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
